# app/main.py

"""
Main entry point for the GenAI chatbot application.
This FastAPI app exposes a simple /chat endpoint that accepts a user message
and returns a response generated by a language model (e.g., GPT-2 or other LLM).
"""

from fastapi import FastAPI, Request
from pydantic import BaseModel
from app.chat_engine import generate_response  # Custom logic (to be implemented)

app = FastAPI(title="GenAI Chatbot", version="0.1")

# Define input structure using Pydantic
class ChatInput(BaseModel):
    message: str

# Define output structure
class ChatOutput(BaseModel):
    response: str

@app.post("/chat", response_model=ChatOutput)
async def chat(input_data: ChatInput):
    """
    Handles user chat input and returns generated LLM response.

    Args:
        input_data (ChatInput): JSON payload with 'message'.

    Returns:
        ChatOutput: JSON with generated 'response'.
    """
    user_message = input_data.message

    # Call the model inference logic (placeholder for now)
    response = generate_response(user_message)

    return ChatOutput(response=response)
